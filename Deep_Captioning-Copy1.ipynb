{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deep Reinforcement Learning-based Image Captioning with Embedding Reward\n",
    "Originally made by Pranshu Gupta, Deep Learning @ Georgia Institute of Technology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Working on:  cuda\n"
    }
   ],
   "source": [
    "# As usual, a bit of setup\n",
    "from __future__ import print_function\n",
    "import time, os, json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "from torchtext.data.metrics import bleu_score\n",
    "\n",
    "from utils.coco_utils import load_coco_data, sample_coco_minibatch, decode_captions\n",
    "from utils.image_utils import image_from_url\n",
    "from models.nets import PolicyNetwork, RewardNetwork, ValueNetwork\n",
    "from search.search import GenerateCaptions, GenerateCaptionsWithBeamSearch\n",
    "from torchsummary import summary\n",
    "import metrics\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "# for auto-reloading external modules\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Working on: \", device)\n",
    "\n",
    "def rel_error(x, y):\n",
    "    \"\"\" returns relative error \"\"\"\n",
    "    return np.max(np.abs(x - y) / (np.maximum(1e-8, np.abs(x) + np.abs(y))))\n",
    "\n",
    "max_seq_len = 17\n",
    "\n",
    "def softmax(x):\n",
    "    \"\"\"Compute softmax values for each sets of scores in x.\"\"\"\n",
    "    e_x = np.exp(x - np.max(x))\n",
    "    return e_x / e_x.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load MS-COCO data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load COCO data from disk; this returns a dictionary\n",
    "# We'll work with dimensionality-reduced features for this notebook, but feel\n",
    "# free to experiment with the original features by changing the flag below.\n",
    "data = load_coco_data(pca_features=True)\n",
    "\n",
    "data[\"train_captions_lens\"] = np.zeros(data[\"train_captions\"].shape[0])\n",
    "data[\"val_captions_lens\"] = np.zeros(data[\"val_captions\"].shape[0])\n",
    "for i in range(data[\"train_captions\"].shape[0]):\n",
    "    data[\"train_captions_lens\"][i] = np.nonzero(data[\"train_captions\"][i] == 2)[0][0] + 1\n",
    "for i in range(data[\"val_captions\"].shape[0]):\n",
    "    data[\"val_captions_lens\"][i] = np.nonzero(data[\"val_captions\"][i] == 2)[0][0] + 1\n",
    "\n",
    "\n",
    "# Print out all the keys and values from the data dictionary\n",
    "# for k, v in data.items():\n",
    "#     if type(v) == np.ndarray:\n",
    "#         print(k, type(v), v.shape, v.dtype)\n",
    "#     else:\n",
    "#         print(k, type(v), len(v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_data = load_coco_data(max_train=50000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Caption Evaluation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BLEU_score(gt_caption, sample_caption, w):\n",
    "    \"\"\"\n",
    "    gt_caption: string, ground-truth caption\n",
    "    sample_caption: string, your model's predicted caption\n",
    "    Returns unigram BLEU score.\n",
    "    \"\"\"\n",
    "    try: \n",
    "        reference = [x for x in gt_caption.split(' ') \n",
    "                     if ('<END>' not in x and '<START>' not in x and '<UNK>' not in x)]\n",
    "        hypothesis = [x for x in sample_caption.split(' ') \n",
    "                      if ('<END>' not in x and '<START>' not in x and '<UNK>' not in x)]\n",
    "        \n",
    "    except AttributeError:\n",
    "        reference = [x for x in gt_caption\n",
    "                     if ('<END>' not in x and '<START>' not in x and '<UNK>' not in x)]\n",
    "        hypothesis = [x for x in sample_caption\n",
    "                      if ('<END>' not in x and '<START>' not in x and '<UNK>' not in x)]\n",
    "        \n",
    "    BLEUscore = nltk.translate.bleu_score.sentence_bleu([reference], hypothesis, weights = [w])\n",
    "    return BLEUscore\n",
    "\n",
    "def BLEU_tensor(captions_in, target_caption):\n",
    "    idx_to_word = {i : w for w, i in data[\"word_to_idx\"].items()}\n",
    "    source = []\n",
    "    target = []\n",
    "    \n",
    "    for i in range(captions_in.shape[1]):\n",
    "        source.append(idx_to_word[captions_in[0][i].item()])\n",
    "        \n",
    "    for i in range(target_caption.shape[1]):\n",
    "        target.append(idx_to_word[target_caption[0][i].item()])\n",
    "    \n",
    "    b1 = BLEU_score(source, target,1)\n",
    "    b2 = BLEU_score(source, target,2)\n",
    "    b3 = BLEU_score(source, target,3)\n",
    "    b4 = BLEU_score(source, target,4)\n",
    "    return 0.5 * b1 + 0.5 * b2 + b3 + b4\n",
    "\n",
    "def evaluate_model(model):\n",
    "    \"\"\"\n",
    "    model: CaptioningRNN model\n",
    "    Prints unigram BLEU score averaged over 1000 training and val examples.\n",
    "    \"\"\"\n",
    "    BLEUscores = {}\n",
    "    for split in ['train', 'val']:\n",
    "        minibatch = sample_coco_minibatch(data, split=split, batch_size=1000)\n",
    "        gt_captions, features, urls = minibatch\n",
    "        gt_captions = decode_captions(gt_captions, data['idx_to_word'])\n",
    "\n",
    "        sample_captions = model.sample(features)\n",
    "        sample_captions = decode_captions(sample_captions, data['idx_to_word'])\n",
    "\n",
    "        total_score = 0.0\n",
    "        for gt_caption, sample_caption, url in zip(gt_captions, sample_captions, urls):\n",
    "            total_score += BLEU_score(gt_caption, sample_caption)\n",
    "\n",
    "        BLEUscores[split] = total_score / len(sample_captions)\n",
    "\n",
    "    for split in BLEUscores:\n",
    "        print('Average BLEU score for %s: %f' % (split, BLEUscores[split]))\n",
    "        \n",
    "# ref, hypo = metrics.load_textfiles(tru_caps, gen_caps)\n",
    "# print(metrics.score(ref, hypo))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Baseline (Trained only on BLEU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# baseline = RewardNetwork(data[\"word_to_idx\"]).to(device)\n",
    "# baseline.load_state_dict(torch.load('./pretrained/rewardNetwork_pre.pt')\n",
    "class BaselineNetwork(nn.Module):\n",
    "    def __init__(self, word_to_idx, batch_size=10, wordvec_dim=512):\n",
    "        super().__init__()\n",
    "        vocab_size = len(word_to_idx)\n",
    "        self.batch_size = batch_size\n",
    "        self.caption_embedding = nn.Embedding(vocab_size, wordvec_dim)\n",
    "        \n",
    "        self.scoring1 = nn.Linear(16 * 512, 512)\n",
    "        self.scoring2 = nn.Linear(512, 1)\n",
    "        \n",
    "    def forward(self, captions, train=True):\n",
    "        \n",
    "        input_captions = self.caption_embedding(captions)\n",
    "        if train == False:\n",
    "            margin = torch.zeros(1, 16 - input_captions.shape[1], 512).to(device)\n",
    "            input_captions = torch.cat((input_captions, margin), dim=1)\n",
    "            input_captions = input_captions.view(1, -1)\n",
    "          \n",
    "        else:\n",
    "            margin = torch.zeros(self.batch_size, 16 - input_captions.shape[1], 512).to(device)\n",
    "            input_captions = torch.cat((input_captions, margin), dim=1)\n",
    "            input_captions = input_captions.view(self.batch_size, -1)\n",
    "        output = self.scoring1(input_captions)\n",
    "        output = self.scoring2(output)\n",
    "        output = output.squeeze(1)\n",
    "        return output\n",
    "\n",
    "baseline = BaselineNetwork(data[\"word_to_idx\"]).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# policyNet = PolicyNetwork(data[\"word_to_idx\"]).to(device)\n",
    "# policyNet.load_state_dict(torch.load('./pretrained/policyNetwork_pre2.pt'))\n",
    "criterion = nn.MSELoss().to(device)\n",
    "optimizer = optim.Adam(baseline.parameters(), lr=0.001)\n",
    "\n",
    "caps0 = []\n",
    "caps1 = []\n",
    "\n",
    "f = open(\"./results/truth3.txt\", \"r\")\n",
    "for x in f:\n",
    "    x = \" \".join([w for w in x.split(' ') if ('<END>' not in w and '<START>' not in w and '<UNK>' not in w)])\n",
    "    caps0.append(x)\n",
    "f = open(\"./results/greedy3.txt\", \"r\")\n",
    "for x in f:\n",
    "    x = \" \".join([w for w in x.split(' ') if ('<END>' not in w and '<START>' not in w and '<UNK>' not in w)])\n",
    "    caps1.append(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'baseline' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-0964567e2ced>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mbaseline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mcaps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'baseline' is not defined"
     ]
    }
   ],
   "source": [
    "epochs = 10000\n",
    "bestLoss = 10\n",
    "batch_size = 10\n",
    "\n",
    "baseline.train()\n",
    "for epoch in range(epochs):\n",
    "    caps = []\n",
    "    bs = []\n",
    "    \n",
    "    i = epoch\n",
    "    for _ in range(batch_size):\n",
    "        i %= len(caps0)\n",
    "        b1 = BLEU_score(caps0[i], caps1[i], 1)\n",
    "        b2 = BLEU_score(caps0[i], caps1[i], 2)\n",
    "        b3 = BLEU_score(caps0[i], caps1[i], 3)\n",
    "        b4 = BLEU_score(caps0[i], caps1[i], 4)\n",
    "        b = 0.5 * b1 + 0.5 * b2 + b3 + b4\n",
    "        bs.append(b)\n",
    "        \n",
    "        cap = caps1[i].split()\n",
    "        for j in range(len(cap)):\n",
    "            cap[j] = data[\"word_to_idx\"][cap[j]]\n",
    "        while(len(cap) < 16):\n",
    "            cap.append(0)\n",
    "        \n",
    "        caps.append(cap)\n",
    "        i += 1\n",
    "        \n",
    "    caps = torch.tensor(caps).to(device)\n",
    "    bs = torch.tensor(bs).to(device)\n",
    "    \n",
    "    output = baseline.forward(caps)\n",
    "    if (epoch == epochs - 1):\n",
    "        print(output, bs)\n",
    "    print(loss.item())\n",
    "    loss = criterion(output, bs)\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if loss.item() < bestLoss or (epoch == epochs-1 and bestLoss == 10):\n",
    "        bestLoss = loss.item()\n",
    "        torch.save(baseline.state_dict(), \"./pretrained/baseline_pre.pt\")\n",
    "        print(\"Best! epoch:\", epoch, \"loss:\", loss.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reinforcement Learning\n",
    "Advantage Actor Critic Model for Reinforcement Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdvantageActorCriticNetwork(nn.Module):\n",
    "    def __init__(self, valueNet, policyNet):\n",
    "        super(AdvantageActorCriticNetwork, self).__init__()\n",
    "\n",
    "        self.valueNet = valueNet #RewardNetwork(data[\"word_to_idx\"]).to(device)\n",
    "        self.policyNet = policyNet #PolicyNetwork(data[\"word_to_idx\"]).to(device)\n",
    "\n",
    "    def forward(self, features, captions):\n",
    "        # Get value from value network\n",
    "        values = self.valueNet(features, captions)\n",
    "        # Get action probabilities from policy network\n",
    "        probs = self.policyNet(features.unsqueeze(0), captions)[:, -1:, :]        \n",
    "        return values, probs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "policy pre2 loaded\nvalid pre2 loaded\n"
    }
   ],
   "source": [
    "policyNet = PolicyNetwork(data[\"word_to_idx\"]).to(device)\n",
    "valueNet = ValueNetwork(data[\"word_to_idx\"]).to(device)\n",
    "baseline = BaselineNetwork(data[\"word_to_idx\"]).to(device)\n",
    "\n",
    "if (os.path.exists('./pretrained/policyNetwork_pre2.pt')):\n",
    "    policyNet.load_state_dict(torch.load('./pretrained/policyNetwork_pre2.pt'))\n",
    "    print(\"policy pre2 loaded\")\n",
    "else:\n",
    "    policyNet.load_state_dict(torch.load('./pretrained/policyNetwork_pre.pt'))\n",
    "\n",
    "if (os.path.exists('./pretrained/valueNetwork_pre2.pt')):\n",
    "    valueNet.load_state_dict(torch.load('./pretrained/valueNetwork_pre2.pt'))\n",
    "    print(\"valid pre2 loaded\")\n",
    "else:\n",
    "    valueNet.load_state_dict(torch.load('./pretrained/valueNetwork_pre.pt'))\n",
    "\n",
    "baseline.load_state_dict(torch.load('./pretrained/baseline_pre.pt'))\n",
    "    \n",
    "a2cNetwork = AdvantageActorCriticNetwork(valueNet, policyNet)\n",
    "optimizer = optim.Adam(a2cNetwork.parameters(), lr=0.0001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Curriculum Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "<UNK>\n"
    }
   ],
   "source": [
    "a = torch.tensor(3)\n",
    "word_to_idx = {w : i for i, w in data[\"word_to_idx\"].items()}\n",
    "b = word_to_idx[a.item()]\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "output_type": "error",
     "ename": "TypeError",
     "evalue": "len() of a 0-d tensor",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-02a60847ff4b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     79\u001b[0m             \u001b[0mtarget_caption\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcaptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mepisode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mepisode\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m             \u001b[0mq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbleu_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcaptions_in\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_caption\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m             \u001b[0mq\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mBLEU_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcaptions_in2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_caption\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m             \u001b[0mq\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mBLEU_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcaptions_in3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_caption\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torchtext/data/metrics.py\u001b[0m in \u001b[0;36mbleu_score\u001b[0;34m(candidate_corpus, references_corpus, max_n, weights)\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0;31m# Get the length of the reference that's closest in length to the candidate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m         \u001b[0mrefs_len_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mref\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mref\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrefs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m         \u001b[0mrefs_len\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrefs_len_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcandidate\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torchtext/data/metrics.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0;31m# Get the length of the reference that's closest in length to the candidate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m         \u001b[0mrefs_len_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mref\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mref\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrefs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m         \u001b[0mrefs_len\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrefs_len_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcandidate\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36m__len__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    449\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 451\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"len() of a 0-d tensor\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    452\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: len() of a 0-d tensor"
     ]
    }
   ],
   "source": [
    "episodes = 50\n",
    "epochs = 20 #1000 but out of memory...\n",
    "small_data = load_coco_data(max_train=50000)\n",
    "bestLoss = 1.0\n",
    "optimizer = optim.Adam(a2cNetwork.parameters(), lr=0.0001)\n",
    "word_to_idx = {w : i for i, w in data[\"word_to_idx\"].items()}\n",
    "\n",
    "for epoch in range(epochs): \n",
    "    episodicAvgLoss = 0\n",
    "\n",
    "    captions, features, _ = sample_coco_minibatch(small_data, batch_size=episodes, split='train')\n",
    "    features = torch.tensor(features, device=device).float() \n",
    "    captions = torch.tensor(captions, device=device).long()\n",
    "    \n",
    "    for episode in range(episodes):\n",
    "        log_probs = []\n",
    "        values = []\n",
    "        rewards = []\n",
    "        caplen = np.nonzero(captions[episode] == 2)[0][0] + 1\n",
    "        gen_cap = 0\n",
    "        \n",
    "\n",
    "        captions_in = captions[episode:episode+1, :2]\n",
    "        features_in = features[episode:episode+1]\n",
    "\n",
    "        value, probs = a2cNetwork(features_in, captions_in)\n",
    "        \n",
    "        while(captions_in.shape[1] < 16 and gen_cap != 2): #Generate Sequence g1:T \n",
    "\n",
    "            value, probs = a2cNetwork(features_in, captions_in)\n",
    "            probs = F.softmax(probs, dim=2)\n",
    "\n",
    "            dist = probs.cpu().detach().numpy()[0,0]\n",
    "            action = np.random.choice(probs.shape[-1], p=dist)\n",
    "            \n",
    "            gen_cap = torch.from_numpy(np.array([action])).unsqueeze(0).to(device)\n",
    "            captions_in = torch.cat((captions_in, gen_cap), axis=1)\n",
    "            \n",
    "        \n",
    "        len_caption = captions_in.shape[1]\n",
    "\n",
    "        loss_V = 0\n",
    "        loss_L = 0\n",
    "        for t in range(len_caption):  # Compute the Q and B for every t in range from 1 to T\n",
    "            captions_in = captions[episode:episode+1, : t+1]\n",
    "            captions_in2 = captions[episode:episode+1, : t+1]\n",
    "            captions_in3 = captions[episode:episode+1, : t+1]\n",
    "\n",
    "            features_in = features[episode:episode+1]\n",
    "            b = baseline.forward(captions_in, train=False)\n",
    "            gen_cap = 0\n",
    "            first = 1\n",
    "\n",
    "            while(captions_in.shape[1] < 16 and gen_cap != 2): #Generate Sequence g1:T  for calculating Q\n",
    "                \n",
    "                value, probs = a2cNetwork(features_in, captions_in)\n",
    "\n",
    "                probs = F.softmax(probs, dim=2)\n",
    "                \n",
    "                dist = probs.cpu().detach().numpy()[0,0]\n",
    "                action = np.random.choice(probs.shape[-1], p=dist)\n",
    "                action2 = np.random.choice(probs.shape[-1], p=dist)\n",
    "                action3 = np.random.choice(probs.shape[-1], p=dist)\n",
    "\n",
    "                gen_cap = torch.from_numpy(np.array([action])).unsqueeze(0).to(device)\n",
    "                gen_cap2 = torch.from_numpy(np.array([action2])).unsqueeze(0).to(device)\n",
    "                gen_cap3 = torch.from_numpy(np.array([action3])).unsqueeze(0).to(device)\n",
    "                \n",
    "                captions_in = torch.cat((captions_in, gen_cap), axis=1)\n",
    "                captions_in2 = torch.cat((captions_in2, gen_cap2), axis=1)\n",
    "                captions_in3 = torch.cat((captions_in3, gen_cap3), axis=1)\n",
    "\n",
    "                if(first == 1):\n",
    "                    first = 0\n",
    "                    p = probs[0, 0, action]\n",
    "\n",
    "                    \n",
    "            \n",
    "        \n",
    "            target_caption = captions[episode:episode+1]\n",
    "                \n",
    "            q = bleu_score(captions_in, target_caption)\n",
    "            q += BLEU_tensor(captions_in2, target_caption)\n",
    "            q += BLEU_tensor(captions_in3, target_caption)\n",
    "            q /= 3.0\n",
    "            print(p, q, b[0])\n",
    "            if (first == 1): continue\n",
    "            loss_V += (p * (q - b[0]))\n",
    "            loss_L += (q - b[0])**2\n",
    "        \n",
    "        loss = loss_V + loss_L\n",
    "        \n",
    "        episodicAvgLoss += loss.item()/episodes\n",
    "\n",
    "        baseline.eval()\n",
    "        policyNet.train()\n",
    "        optimizer.zero_grad()\n",
    "        loss_V.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        baseline.train()\n",
    "        policyNet.eval()\n",
    "        optimizer.zero_grad()\n",
    "        loss_L.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print(\"epoch:\", epoch, episodicAvgLoss)\n",
    "        \n",
    "\n",
    "\n",
    "torch.save(policyNet.state_dict(), \"./pretrained/policyNetwork_final.pt\")\n",
    "torch.save(baseline.state_dict(), \"./pretrained/BaselineNetwork_final.pt\")\n",
    "\n",
    "print(\"Models are saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'PolicyNetwork' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-5a12b61a8e21>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpolicyNet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPolicyNetwork\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"word_to_idx\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mpolicyNet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./pretrained/policyNetwork_pre2.pt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mvalueNet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mValueNetwork\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"word_to_idx\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mvalueNet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./pretrained/valueNetwork_pre2.pt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'PolicyNetwork' is not defined"
     ]
    }
   ],
   "source": [
    "policyNet = PolicyNetwork(data[\"word_to_idx\"]).to(device)\n",
    "policyNet.load_state_dict(torch.load('./pretrained/policyNetwork_pre2.pt'))\n",
    "valueNet = ValueNetwork(data[\"word_to_idx\"]).to(device)\n",
    "valueNet.load_state_dict(torch.load('./pretrained/valueNetwork_pre2.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('results/policyvalue4.txt', 'w'):\n",
    "    pass\n",
    "with open('results/truth4.txt', 'w'):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-e4af28519e9b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mnum_of_sentences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m150\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mmax_seq_len\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m17\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mcaptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample_coco_minibatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msmall_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msplit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'val'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "num_of_sentences = 150\n",
    "\n",
    "with torch.no_grad():\n",
    "    max_seq_len = 17\n",
    "    captions, features, urls = sample_coco_minibatch(small_data, batch_size=1000, split='val')\n",
    "    gen_caps = []\n",
    "    tru_caps = []\n",
    "    with open('results/policyvalue4.txt', mode='w') as f:\n",
    "        with open('results/truth4.txt', mode='w') as f2:\n",
    "            count = 0\n",
    "            \n",
    "            for i in range(num_of_sentences):\n",
    "                try:    #pass if the url doesnt exist\n",
    "                    plt.imshow(image_from_url(urls[i]))\n",
    "                    count += 1\n",
    "                except:\n",
    "                    continue\n",
    "                if count >= 101: \n",
    "                    break \n",
    "                decoded_tru_caps = decode_captions(captions[i], data[\"idx_to_word\"])\n",
    "                gen_cap = GenerateCaptionsWithBeamSearchValueScoring(features[i:i+1], captions[i:i+1], policyNet)[0][0][0]\n",
    "                decoded_gen_caps = decode_captions(gen_cap, data[\"idx_to_word\"])\n",
    "\n",
    "\n",
    "                f.writelines(' '.join(decoded_gen_caps))\n",
    "                f.write('\\n')\n",
    "\n",
    "                f2.writelines(' '.join(decoded_tru_caps))\n",
    "                f2.write('\\n')\n",
    "                \n",
    "                print(\"Truth   : \", decoded_tru_caps) \n",
    "                print(\"Output: \", decoded_gen_caps) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "tru_caps = []\n",
    "gen_caps = []\n",
    "\n",
    "f = open(\"./results/truth4.txt\", \"r\")\n",
    "for x in f:\n",
    "    x = \" \".join([w for w in x.split(' ') if ('<END>' not in w and '<START>' not in w and '<UNK>' not in w)])\n",
    "    tru_caps.append(x)\n",
    "    \n",
    "f = open(\"./results/policyvalue4.txt\", \"r\")\n",
    "for x in f:\n",
    "    x = \" \".join([w for w in x.split(' ') if ('<END>' not in w and '<START>' not in w and '<UNK>' not in w)])\n",
    "    gen_caps.append(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "BLEU-1 : 0\nBLEU-2 : 0\nBLEU-3 : 0\nBLEU-4 : 0\n"
    }
   ],
   "source": [
    "bleu = 0\n",
    "for w in range(1, 5):\n",
    "    for i in range(len(tru_caps)):\n",
    "\n",
    "        bleu += BLEU_score(tru_caps[i], gen_caps[i], w)\n",
    "        bleu /= len(tru_caps)\n",
    "\n",
    "    print(\"BLEU-\" + str(w), \":\", bleu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'metrics' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-6c30e72f6c93>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mref\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhypo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_textfiles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtru_caps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgen_caps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mref\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhypo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'metrics' is not defined"
     ]
    }
   ],
   "source": [
    "ref, hypo = metrics.load_textfiles(tru_caps, gen_caps)\n",
    "print(metrics.score(ref, hypo))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.9 64-bit",
   "language": "python",
   "name": "python_defaultSpec_1594172492423"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}